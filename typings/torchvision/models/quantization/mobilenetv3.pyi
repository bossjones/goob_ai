"""
This type stub file was generated by pyright.
"""

from typing import Any, Optional, Union
from torch import Tensor
from ...ops.misc import SqueezeExcitation
from .._api import WeightsEnum, register_model
from .._utils import handle_legacy_interface
from ..mobilenetv3 import InvertedResidual, MobileNetV3, MobileNet_V3_Large_Weights

__all__ = ["QuantizableMobileNetV3", "MobileNet_V3_Large_QuantizedWeights", "mobilenet_v3_large"]
class QuantizableSqueezeExcitation(SqueezeExcitation):
    _version = ...
    def __init__(self, *args: Any, **kwargs: Any) -> None:
        ...
    
    def forward(self, input: Tensor) -> Tensor:
        ...
    
    def fuse_model(self, is_qat: Optional[bool] = ...) -> None:
        ...
    


class QuantizableInvertedResidual(InvertedResidual):
    def __init__(self, *args: Any, **kwargs: Any) -> None:
        ...
    
    def forward(self, x: Tensor) -> Tensor:
        ...
    


class QuantizableMobileNetV3(MobileNetV3):
    def __init__(self, *args: Any, **kwargs: Any) -> None:
        """
        MobileNet V3 main class

        Args:
           Inherits args from floating point MobileNetV3
        """
        ...
    
    def forward(self, x: Tensor) -> Tensor:
        ...
    
    def fuse_model(self, is_qat: Optional[bool] = ...) -> None:
        ...
    


class MobileNet_V3_Large_QuantizedWeights(WeightsEnum):
    IMAGENET1K_QNNPACK_V1 = ...
    DEFAULT = ...


@register_model(name="quantized_mobilenet_v3_large")
@handle_legacy_interface(weights=("pretrained", lambda kwargs: MobileNet_V3_Large_QuantizedWeights.IMAGENET1K_QNNPACK_V1 if kwargs.get("quantize", False) else MobileNet_V3_Large_Weights.IMAGENET1K_V1))
def mobilenet_v3_large(*, weights: Optional[Union[MobileNet_V3_Large_QuantizedWeights, MobileNet_V3_Large_Weights]] = ..., progress: bool = ..., quantize: bool = ..., **kwargs: Any) -> QuantizableMobileNetV3:
    """
    MobileNetV3 (Large) model from
    `Searching for MobileNetV3 <https://arxiv.org/abs/1905.02244>`_.

    .. note::
        Note that ``quantize = True`` returns a quantized model with 8 bit
        weights. Quantized models only support inference and run on CPUs.
        GPU inference is not yet supported.

    Args:
        weights (:class:`~torchvision.models.quantization.MobileNet_V3_Large_QuantizedWeights` or :class:`~torchvision.models.MobileNet_V3_Large_Weights`, optional): The
            pretrained weights for the model. See
            :class:`~torchvision.models.quantization.MobileNet_V3_Large_QuantizedWeights` below for
            more details, and possible values. By default, no pre-trained
            weights are used.
        progress (bool): If True, displays a progress bar of the
            download to stderr. Default is True.
        quantize (bool): If True, return a quantized version of the model. Default is False.
        **kwargs: parameters passed to the ``torchvision.models.quantization.MobileNet_V3_Large_QuantizedWeights``
            base class. Please refer to the `source code
            <https://github.com/pytorch/vision/blob/main/torchvision/models/quantization/mobilenetv3.py>`_
            for more details about this class.

    .. autoclass:: torchvision.models.quantization.MobileNet_V3_Large_QuantizedWeights
        :members:
    .. autoclass:: torchvision.models.MobileNet_V3_Large_Weights
        :members:
        :noindex:
    """
    ...

