{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f5a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import dotenv\n",
    "\n",
    "\n",
    "# Reload the variables in your '.env' file (override the existing variables)\n",
    "dotenv.load_dotenv(\"../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94811d54",
   "metadata": {},
   "source": [
    "# Run basic example from Langchain Vectorstores Chroma page\n",
    "\n",
    "[Read more here](https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dade7d86",
   "metadata": {},
   "source": [
    "# Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe3e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "from goob_ai import debugger\n",
    "import logging\n",
    "import shutil\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import TYPE_CHECKING, Any, List, Tuple\n",
    "\n",
    "import faiss\n",
    "\n",
    "from goob_ai.services import (\n",
    "    answer_question_from_context,\n",
    "    bm25_retrieval,\n",
    "    create_question_answer_from_context_chain,\n",
    "    encode_from_string,\n",
    "    encode_pdf,\n",
    "    get_chunk_by_index,\n",
    "    read_pdf_to_string,\n",
    "    replace_t_with_space,\n",
    "    retrieve_context_per_question,\n",
    "    retrieve_with_context_overlap,\n",
    "    show_context,\n",
    "    split_text_to_chunks_with_indices,\n",
    "    text_wrap,\n",
    ")\n",
    "from langchain.vectorstores import FAISS, VectorStore\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSerializable\n",
    "from langchain_core.vectorstores.base import VectorStoreRetriever\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from loguru import logger as LOGGER\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "from goob_ai.bot_logger import get_logger, global_log_config\n",
    "from goob_ai.aio_settings import aiosettings, get_rich_console\n",
    "\n",
    "\n",
    "global_log_config(\n",
    "    log_level=logging.getLevelName(\"DEBUG\"),\n",
    "    json=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbc8f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "path = \"example_data/Understanding_Climate_Change.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb21c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faiss_vector_store(path_to_pdf: Path, chunk_size: int = 400, chunk_overlap: int = 200) -> Tuple[VectorStore, List[Document], str]:\n",
    "    content = read_pdf_to_string(f\"{path_to_pdf}\")\n",
    "    docs = split_text_to_chunks_with_indices(content, chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "    # This line creates a Faiss index using the IndexFlatL2 class. The dimension of the index is determined by the length of the embedding generated for the query \"hello world\".\n",
    "    index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "    # This line creates an instance of the FAISS vector store, specifying the embedding function (embeddings), the Faiss index (index), an in-memory document store (InMemoryDocstore()), and an empty dictionary to map index IDs to document store IDs.\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        docs, embeddings, index=index, docstore_cls=InMemoryDocstore(), index_to_docstore_id={}\n",
    "    )\n",
    "    return vectorstore, docs, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0021cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore, docs, content = get_faiss_vector_store(path)\n",
    "\n",
    "chunks_query_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = get_chunk_by_index(vectorstore, 0)\n",
    "rich.print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bed1d3",
   "metadata": {},
   "source": [
    "# Comparing regular retrival and retrival with context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline approach\n",
    "query = \"Explain the role of deforestation and fossil fuels in climate change.\"\n",
    "baseline_chunk = chunks_query_retriever.get_relevant_documents(query\n",
    "    ,\n",
    "    k=1\n",
    ")\n",
    "# Focused context enrichment approach\n",
    "enriched_chunks = retrieve_with_context_overlap(\n",
    "    vectorstore,\n",
    "    chunks_query_retriever,\n",
    "    query,\n",
    "    num_neighbors=1,\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "\n",
    "rich.print(\"Baseline Chunk:\")\n",
    "rich.print(baseline_chunk[0].page_content)\n",
    "rich.print(\"\\nEnriched Chunks:\")\n",
    "rich.print(enriched_chunks[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
